{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to train the model.\n",
    "\n",
    "Dataset:\n",
    "    lib/Datasets.py:\n",
    "        EEGDataset\n",
    "\n",
    "Models:\n",
    "    lib/models/EEG_Net_CNN.py : EEG_Net_CNN - a simple convolutional neural network [conv -> conv -> conv -> dense] with ELU activation, pooling, and batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from lib.models.EEG_Net_CNN import EEG_Net_CNN\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.utils import load_data, train, test\n",
    "from lib.Datasets import EEGDataset\n",
    "from lib.DataObject import DataObject\n",
    "import lib.DataObjectUtils as util\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from lib.DataHandler import DataAcquisitionHandler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle files\n",
    "filepath = \"C:/Users/c25th/code/P300_BCI_Speller/\"\n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "train_filename = \"data/dataloaders/train_loader_\"+str(date)+\".txt\"\n",
    "val_filename = \"data/dataloaders/val_loader_\"+str(date)+\".txt\"\n",
    "test_filename = \"data/dataloaders/test_loader_\"+str(date)+\".txt\"\n",
    "\n",
    "train_loader = torch.load(filepath + train_filename)\n",
    "val_loader = torch.load(filepath + val_filename)\n",
    "test_loader = torch.load(filepath + test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# create p300Model\n",
    "class EEG_Net_CNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch implementation of EEGNet\n",
    "\n",
    "    Expecting input of shape (batch_size, channels, readings)\n",
    "    input = [32, 8, 250] = [batch_size, channels, readings]\n",
    "    batch_size: number of samples in a batch\n",
    "    channels: number of channels in a sample (8)\n",
    "    readings: number of readings in a channel (len())\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_channels=8, num_classes=2, input_length=250):\n",
    "        super(EEG_Net_CNN, self).__init__()\n",
    "\n",
    "        # Conv1\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            nn.Conv1d(num_channels, 16, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool1d(kernel_size=4, stride=4, padding=0)\n",
    "            # nn.Dropout(p=0.25)\n",
    "        )\n",
    "\n",
    "        # Conv2\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool1d(kernel_size=4, stride=4, padding=0)\n",
    "            # nn.Dropout(p=0.25)\n",
    "        )\n",
    "\n",
    "        # Conv3\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool1d(kernel_size=4, stride=4, padding=0)\n",
    "            # nn.Dropout(p=0.25)\n",
    "        )\n",
    "\n",
    "        # Conv4\n",
    "        self.conv4 = torch.nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool1d(kernel_size=4, stride=4, padding=0)\n",
    "            # nn.Dropout(p=0.25)\n",
    "        )\n",
    "\n",
    "        # Conv5\n",
    "        self.conv5 = torch.nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ELU(alpha=1.0),\n",
    "            nn.AvgPool1d(kernel_size=4, stride=4, padding=0)\n",
    "            # nn.Dropout(p=0.25)\n",
    "        )\n",
    "\n",
    "        # Output\n",
    "        self.out = torch.nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv3(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv4(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv5(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.shape)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = EEG_Net_CNN()\n",
    "\n",
    "# loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 250])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x5984 and 128x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\c25th\\code\\P300_BCI_Speller\\model_training.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/c25th/code/P300_BCI_Speller/model_training.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# def train_and_validate(train_dataloader, val_dataloader, model, loss_fn, optimizer, num_epochs, print_every=100):\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/c25th/code/P300_BCI_Speller/model_training.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_losses, val_losses, train_accuracies, val_accuracies \u001b[39m=\u001b[39m train(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/c25th/code/P300_BCI_Speller/model_training.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_loader, val_loader, model, loss_fn, optimizer, \u001b[39m100\u001b[39;49m, print_every\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\c25th\\code\\P300_BCI_Speller\\model_training.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c25th/code/P300_BCI_Speller/model_training.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c25th/code/P300_BCI_Speller/model_training.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/c25th/code/P300_BCI_Speller/model_training.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c25th/code/P300_BCI_Speller/model_training.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c25th/code/P300_BCI_Speller/model_training.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\c25th\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\c25th\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\c25th\\code\\P300_BCI_Speller\\lib\\models\\EEG_Net_CNN.py:84\u001b[0m, in \u001b[0;36mEEG_Net_CNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[39m# fc\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc(x)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\c25th\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\c25th\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\c25th\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x5984 and 128x2)"
     ]
    }
   ],
   "source": [
    "# def train_and_validate(train_dataloader, val_dataloader, model, loss_fn, optimizer, num_epochs, print_every=100):\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train(\n",
    "    train_loader, val_loader, model, loss_fn, optimizer, 100, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Train Accuracy:  0.536441828881847\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 0.701727 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum Train Accuracy: \", max(train_accuracies))\n",
    "test(test_loader, model, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
